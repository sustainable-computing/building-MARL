{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bcf34f",
   "metadata": {},
   "source": [
    "# Continuous Offline Policy Evaluation\n",
    "\n",
    "Testing continuous offline policy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49d6db-21c6-4160-9db3-4cc4cf4323a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "sys.path.insert(0, \"../\")\n",
    "import torch\n",
    "from ppo import PPO\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "from obp.ope import (\n",
    "    ContinuousOffPolicyEvaluation,\n",
    "    KernelizedInverseProbabilityWeighting,\n",
    ")\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa01c79-6bc9-49ce-8049-7dd90b2c9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = pd.read_csv(\"../data/rule_based_log_data/<name_of_building>/log_data.csv\")\n",
    "with open(\"../data/rule_based_log_data/<name_of_building>/action_probs_all_data.pkl\", \"rb\") as f:\n",
    "    behavior_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd83be-0587-4bb3-924f-247eed8fd78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ts_per_day = 4 * 24\n",
    "num_days = 15  # Number of days to consider for evaluation\n",
    "ts_end = num_ts_per_day * num_days\n",
    "zones = log_data[\"zone\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3379e76-e17f-4df8-bad9-80bc1c948eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_list = sorted(list(glob.glob(f\"../policy_library_20220705/**.pth\")))\n",
    "invalid_policies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316029f7-caf8-4428-8751-9b25fc6cedca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_policy_scores(config, use_progress_bar=False):\n",
    "    policy_scores = {}\n",
    "    kernel = config[\"kernel\"]\n",
    "    bandwidth = config[\"bandwidth\"]\n",
    "    for zone in zones:\n",
    "        # print(zone)\n",
    "        ope_data = log_data[log_data[\"zone\"] == zone].sort_values(by=[\"timestep\"])\n",
    "        ope_data = log_data[:ts_end]\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        for i, row in ope_data.iterrows():\n",
    "            state_vars = [\"outdoor_temp\", \"solar_irradiation\", \"time_hour\",\n",
    "                          \"zone_humidity\", \"zone_temp\", \"zone_occupancy\"]\n",
    "            state = [row[var] for var in state_vars]\n",
    "            action = row[\"action\"]\n",
    "            reward = row[\"reward\"]\n",
    "            states.append(state)\n",
    "            rewards.append(reward)\n",
    "            actions.append(action)\n",
    "        ope = ContinuousOffPolicyEvaluation(bandit_feedback=\n",
    "                                            {\"action\": np.array(actions),\n",
    "                                             \"reward\": np.array(rewards),\n",
    "                                             \"pscore\": np.ones((len(ope_data)))},\n",
    "                                            ope_estimators=[KernelizedInverseProbabilityWeighting(kernel=kernel, bandwidth=bandwidth)])\n",
    "        \n",
    "        if use_progress_bar:\n",
    "            policy_iterable = tqdm(policy_list)\n",
    "        else:\n",
    "            policy_iterable = policy_list\n",
    "        for policy in policy_iterable:\n",
    "            agent = PPO(6, 1, 0.003, 0.0005, 1, 10, 0.2,\n",
    "                        has_continuous_action_space=True, action_std_init=0.2, \n",
    "                        device=torch.device('cpu'), diverse_policies=list(),\n",
    "                        diverse_weight=0, diverse_increase=True)\n",
    "            agent.load(policy)\n",
    "            agent.policy_evaluation = False\n",
    "            agent.policy_old.set_action_std(0.1)\n",
    "\n",
    "            if policy not in invalid_policies:\n",
    "                eval_actions = torch.Tensor(agent.select_action(states)).sigmoid()\n",
    "                estimated_value = ope.estimate_policy_values(action_by_evaluation_policy=eval_actions.numpy())\n",
    "            else:\n",
    "                continue\n",
    "            if policy not in policy_scores:\n",
    "                policy_scores[policy] = {}\n",
    "            if zone not in policy_scores[policy]:\n",
    "                policy_scores[policy][zone] = estimated_value[\"kernelized_ipw\"]\n",
    "    return policy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423bd5d4-3990-4428-b37e-98c0b3985193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zonewise_spearman_corr(policy_scores):\n",
    "    \"\"\"Method to calculate the spearman correlation for this ranking method\n",
    "\n",
    "    This method cannot be used unless the ground truth policy values are know. This method\n",
    "    is not required to run OPE.\n",
    "\n",
    "    Args:\n",
    "        policy_scores (list): The list containing the locations of the policies\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the spearman correlation for each zone\n",
    "    \"\"\"\n",
    "    eval_data_loc = \"../data/evaluation_clean_20220705.csv\"\n",
    "    df = pd.read_csv(eval_data_loc, header=None, names=[\"datetime\",\"policy\",\"zone\",\"energy\"])\n",
    "    spearman_corr = {}\n",
    "    for zone in zones:\n",
    "        eval_df = df[df[\"zone\"] == zone]\n",
    "\n",
    "        # invalid_policies = list(set(policy_list) - set(policy_scores.keys()))\n",
    "        for i_policy in invalid_policies:\n",
    "            eval_df = eval_df[eval_df[\"policy\"]!=i_policy[3:]]\n",
    "        eval_df = eval_df.sort_values(by=[\"energy\"])\n",
    "        score_list = []\n",
    "        for i, row in eval_df.iterrows():\n",
    "            score_list.append(policy_scores[f\"../{row['policy']}\"][zone])\n",
    "\n",
    "        eval_df[\"ope_scores\"] = score_list\n",
    "        correlation = spearmanr(eval_df[\"energy\"].values, eval_df[\"ope_scores\"].values, nan_policy=\"omit\")\n",
    "        spearman_corr[zone] = correlation\n",
    "    return spearman_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4af84b-d982-4af0-92d8-49b14536144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_spearman_corr(config):\n",
    "    policy_scores = get_policy_scores(config)\n",
    "    spearman_corr = calculate_zonewise_spearman_corr(policy_scores)\n",
    "    corrs = []\n",
    "    for zone in spearman_corr:\n",
    "        corrs.append(abs(spearman_corr[zone].correlation))\n",
    "    return np.mean(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec26ae8-f240-42a4-88ee-cd0a0313b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"kernel\": \"gaussian\",\n",
    "    \"bandwidth\": 0.02\n",
    "}\n",
    "policy_scores = get_policy_scores(config)\n",
    "with open(f\"data/<name_of_building>/cont_ipw/raw_scores/cont_ipw_raw_scores_days.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(policy_scores, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('ep_policy_diversity')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "dafb841687ae064af76a00494fc823d3e183411d8e72d0d9b210df7264b4c2fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
