{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607db1a6",
   "metadata": {},
   "source": [
    "# Discrete Offline Policy Evaluation\n",
    "\n",
    "Testing standard discrete offline policy evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "sys.path.insert(0, \"../\")\n",
    "import torch\n",
    "from ppo import PPO\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = pd.read_csv(\"../data/rule_based_log_data/<name_of_building>/0_cleaned_log.csv\")\n",
    "with open(\"../data/rule_based_log_data/<name_of_building>/action_probs_all_data.pkl\", \"rb\") as f:\n",
    "    behavior_model = pickle.load(f)\n",
    "invalid_policies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4728dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the mini-batch size\n",
    "num_ts_per_day = 4 * 24\n",
    "num_days = 15\n",
    "ts_end = num_ts_per_day * num_days\n",
    "zones = log_data[\"zone\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading policies from the policy library\n",
    "policy_list = sorted(list(glob.glob(f\"../policy_library_20220820/**.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b95aa6",
   "metadata": {},
   "source": [
    "### 1. Inverse Probability Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab212710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ope.iw import InverseProbabilityWeighting\n",
    "policy_scores = {}\n",
    "for zone in zones:\n",
    "    print(zone)\n",
    "    ope_data = log_data[log_data[\"zone\"] == zone].sort_values(by=[\"timestep\"])\n",
    "    ope_data = log_data[:ts_end]\n",
    "    ipw = InverseProbabilityWeighting(ope_data, retain_grad_fn=False, univariate_action=True)\n",
    "    for policy in tqdm(policy_list):\n",
    "        agent = PPO(6, 1, 0.003, 0.0005, 1, 10, 0.2,\n",
    "                    has_continuous_action_space=True, action_std_init=0.2, \n",
    "                    device=torch.device('cpu'), diverse_policies=list(),\n",
    "                    diverse_weight=0, diverse_increase=True)\n",
    "        agent.load(policy)\n",
    "        agent.policy_evaluation = True\n",
    "        agent.policy_old.set_action_std(0.1)\n",
    "        if policy not in invalid_policies:\n",
    "            score, _, _, _, _ = ipw.evaluate_policy(agent.select_action, behavior_model, score=\"mean\")\n",
    "        else:\n",
    "            continue\n",
    "        if policy not in policy_scores:\n",
    "            policy_scores[policy] = {}\n",
    "        if zone not in policy_scores[policy]:\n",
    "            policy_scores[policy][zone] = score.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3164e",
   "metadata": {},
   "source": [
    "#### Saving Raw Policy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025854b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/<name_of_building>/ipw/raw_scores/ipw_raw_scores_{num_days}_days.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(policy_scores, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b99d7e",
   "metadata": {},
   "source": [
    "#### Generating and Saving Spearman Correlation (OPTIONAL)\n",
    "\n",
    "This step is done to calculate how well the ranking method works. This requires the ground truth performance of all policies in the policy library on the new building. The ground truth data can only be generated via a brute-force method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_loc = \"../data/evaluation_report_20220820.csv\"\n",
    "df = pd.read_csv(eval_data_loc, header=None, names=[\"datetime\",\"policy\",\"zone\",\"energy\"])\n",
    "spearman_corr = {}\n",
    "for zone in zones:\n",
    "    eval_df = df[df[\"zone\"] == zone]\n",
    "\n",
    "    for i_policy in invalid_policies:\n",
    "        eval_df = eval_df[eval_df[\"policy\"]!=i_policy[3:]]\n",
    "    eval_df = eval_df.sort_values(by=[\"energy\"])\n",
    "    score_list = []\n",
    "    for i, row in eval_df.iterrows():\n",
    "        score_list.append(policy_scores[f\"../{row['policy']}\"][zone])\n",
    "\n",
    "    eval_df[\"ope_scores\"] = score_list\n",
    "    correlation = spearmanr(eval_df[\"energy\"].values, eval_df[\"ope_scores\"].values)\n",
    "    spearman_corr[zone] = correlation\n",
    "\n",
    "\n",
    "\n",
    "with open(f\"data/<name_of_building>/ipw/spearman_corr/ipw_spearman_corr_{num_days}_days.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(spearman_corr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a3605",
   "metadata": {},
   "source": [
    "### 2. Self Normalized Inverse Probability Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991c4c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ope.sniw import SelfNormalizedInverseProbabilityWeighting\n",
    "policy_scores_sniw = {}\n",
    "for zone in zones:\n",
    "    print(zone)\n",
    "    ope_data = log_data[log_data[\"zone\"] == zone].sort_values(by=[\"timestep\"])\n",
    "    ope_data = log_data[:ts_end]\n",
    "    snipw = SelfNormalizedInverseProbabilityWeighting(ope_data)\n",
    "    for policy in tqdm(policy_list):\n",
    "        agent = PPO(6, 1, 0.003, 0.0005, 1, 10, 0.2,\n",
    "                    has_continuous_action_space=True, action_std_init=0.2, \n",
    "                    device=torch.device('cpu'), diverse_policies=list(),\n",
    "                    diverse_weight=0, diverse_increase=True)\n",
    "        agent.load(policy)\n",
    "        agent.policy_evaluation = True\n",
    "        agent.policy_old.set_action_std(0.1)\n",
    "        if policy not in invalid_policies:\n",
    "            score = snipw.evaluate_policy(agent.select_action, behavior_model, score=\"mean\")\n",
    "        else:\n",
    "            continue\n",
    "        if policy not in policy_scores_sniw:\n",
    "            policy_scores_sniw[policy] = {}\n",
    "        if zone not in policy_scores_sniw[policy]:\n",
    "            policy_scores_sniw[policy][zone] = score.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace462a9",
   "metadata": {},
   "source": [
    "#### Saving Raw Policy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b66055",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/<name_of_building>/snipw/raw_scores/snipw_raw_scores_{num_days}_days.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(policy_scores_sniw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505dcf9",
   "metadata": {},
   "source": [
    "#### Generating and Saving Spearman Correlation (OPTIONAL)\n",
    "\n",
    "This step is done to calculate how well the ranking method works. This requires the ground truth performance of all policies in the policy library on the new building. The ground truth data can only be generated via a brute-force method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29990691",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_loc = \"../data/eval_data/evaluation_report_20220820.csv\"\n",
    "df = pd.read_csv(eval_data_loc, header=None, names=[\"datetime\",\"policy\",\"zone\",\"energy\"])\n",
    "spearman_corr_sniw = {}\n",
    "for zone in zones:\n",
    "    eval_df = df[df[\"zone\"] == zone]\n",
    "    for i_policy in invalid_policies:\n",
    "        eval_df = eval_df[eval_df[\"policy\"]!=i_policy[3:]]\n",
    "    eval_df = eval_df.sort_values(by=[\"energy\"])\n",
    "    score_list = []\n",
    "    for i, row in eval_df.iterrows():\n",
    "        score_list.append(policy_scores_sniw[f\"../{row['policy']}\"][zone])\n",
    "\n",
    "    eval_df[\"ope_scores\"] = score_list\n",
    "    correlation = spearmanr(eval_df[\"energy\"].values, eval_df[\"ope_scores\"].values, nan_policy=\"omit\")\n",
    "    spearman_corr_sniw[zone] = correlation\n",
    "\n",
    "with open(f\"data/15zone/snipw/spearman_corr/snipw_spearman_corr_{num_days}_days_19_09_2022.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(spearman_corr_sniw, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('ep_policy_diversity')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "dafb841687ae064af76a00494fc823d3e183411d8e72d0d9b210df7264b4c2fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
